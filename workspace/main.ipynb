{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions\n",
    "\n",
    "This section contains utility functions used across different parts of the codebase. These functions are stored in an external Jupyter notebook file named `utils.ipynb`.\n",
    "\n",
    "## Command: `%run utils.ipynb`\n",
    "\n",
    "The `%run` command is used in Jupyter notebooks to execute the code in another notebook. This allows you to reuse functions, classes, and variables defined in the external notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run utils.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration Class\n",
    "\n",
    "This section contains a configuration class named `CFG` that stores settings and flags for various preprocessing and model tuning steps. These configurations control how data is scaled, encoded, and how models are tuned using Optuna.\n",
    "\n",
    "## Class: `CFG`\n",
    "\n",
    "The `CFG` class is designed to hold configuration settings for scaling, encoding, and model tuning.\n",
    "\n",
    "### Attributes\n",
    "\n",
    "- **Scaling Options**:\n",
    "  - `min_max_scaler` (bool): If `True`, use `MinMaxScaler` for scaling numerical features. Default is `True`.\n",
    "  - `standard_scaler` (bool): If `True`, use `StandardScaler` for scaling numerical features. Default is `False`.\n",
    "  - `robust_scaler` (bool): If `True`, use `RobustScaler` for scaling numerical features. Default is `False`.\n",
    "  - `quantile_transformer` (bool): If `True`, use `QuantileTransformer` for scaling numerical features. Default is `False`.\n",
    "\n",
    "- **Encoding Options**:\n",
    "  - `label_encoder` (bool): If `True`, use `LabelEncoder` for encoding categorical features. Default is `False`.\n",
    "  - `one_hot_encoder` (bool): If `True`, use one-hot encoding for categorical features. Default is `False`.\n",
    "\n",
    "- **Model Tuning Options**:\n",
    "  - `histgbr_optuna` (bool): If `True`, optimize `HistGradientBoostingRegressor` using Optuna. Default is `True`.\n",
    "  - `lgb_optuna` (bool): If `True`, optimize `LGBMRegressor` using Optuna. Default is `True`.\n",
    "  - `xgb_optuna` (bool): If `True`, optimize `XGBRegressor` using Optuna. Default is `True`.\n",
    "  - `catb_optuna` (bool): If `True`, optimize `CatBoostRegressor` using Optuna. Default is `True`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "\n",
    "    min_max_scaler = True\n",
    "    standard_scaler = False\n",
    "    robust_scaler = False\n",
    "    quantile_transformer = False\n",
    "\n",
    "    label_encoder = False\n",
    "    one_hot_encoder = False\n",
    "    \n",
    "    histgbr_optuna = True\n",
    "    lgb_optuna = True\n",
    "    xgb_optuna = True\n",
    "    catb_optuna = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r\"C:\\Users\\ahmet\\VSCode\\GDZ-Datathon\\gdz-datathon-data\\train.csv\")\n",
    "test = pd.read_csv(r\"C:\\Users\\ahmet\\VSCode\\GDZ-Datathon\\gdz-datathon-data\\test.csv\")\n",
    "weather = pd.read_csv(r\"C:\\Users\\ahmet\\VSCode\\GDZ-Datathon\\gdz-datathon-data\\weather.csv\")\n",
    "holidays = pd.read_csv(r\"C:\\Users\\ahmet\\VSCode\\GDZ-Datathon\\gdz-datathon-data\\holidays.csv\")\n",
    "holidays.rename(columns={'Yıl': 'year', 'Ay': 'month', 'Gün': 'day'}, inplace=True)\n",
    "weather.rename(columns={'date': 'tarih', 'name': 'ilce'}, inplace=True)\n",
    "weather['ilce'] = weather['ilce'].str.lower()\n",
    "test['bildirimsiz_sum'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = process_date(train)\n",
    "test = process_date(test)\n",
    "weather = process_date(weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = concatenate(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = process_group(train)\n",
    "test = process_group(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = extract_features_on_weather(weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = weather_df_process(weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = merge_data(train, weather_df, holidays)\n",
    "test = merge_data(test, weather_df, holidays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = extract_date_features(train)\n",
    "test = extract_date_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = calculate_date_sin_cos(train)\n",
    "test = calculate_date_sin_cos(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = categorize_process(train)\n",
    "# test = categorize_process(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_districts_csv(train, \"trains\")\n",
    "save_districts_csv(test, \"tests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ilce_train_dataframes = load_from_folder(r\"C:\\Users\\ahmet\\VSCode\\GDZ-Datathon\\trains\")\n",
    "ilce_test_dataframes = load_from_folder(r\"C:\\Users\\ahmet\\VSCode\\GDZ-Datathon\\tests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ilce, ilce_train_df in ilce_train_dataframes.items():\n",
    "    ilce_test_df = ilce_test_dataframes[ilce]\n",
    "    ilce_train_dataframes[ilce], ilce_test_dataframes[ilce] = ExtractFeatures(CFG()).process(ilce_train_df, ilce_test_df, 'bildirimsiz_sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ilce_train_scaled_dataframes = {}\n",
    "ilce_test_scaled_dataframes = {}\n",
    "for ilce, ilce_train_df in ilce_train_dataframes.items():\n",
    "    ilce_test_df = ilce_test_dataframes[ilce]\n",
    "    ilce_train_scaled_dataframes[ilce], ilce_test_scaled_dataframes[ilce] = Scaler(CFG()).process(ilce_train_df, ilce_test_df, 'bildirimsiz_sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ilce_train_encoded_dataframes = {}\n",
    "ilce_test_encoded_dataframes = {}\n",
    "for ilce, ilce_train_df in ilce_train_scaled_dataframes.items():\n",
    "    ilce_test_df = ilce_test_scaled_dataframes[ilce]\n",
    "    ilce_train_encoded_dataframes[ilce], ilce_test_encoded_dataframes[ilce] = Encoder(CFG()).process(ilce_train_df, ilce_test_df, 'ilce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ilce_train_results = {}\n",
    "for ilce, ilce_df in ilce_train_encoded_dataframes.items():\n",
    "    print(f\"\\nProcessing {ilce} data...\")\n",
    "    ilce_train_results[ilce] = Optuna(CFG()).process(ilce_df, 'ilce', 'bildirimsiz_sum', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating and Printing the Average Lowest MAE Score\n",
    "\n",
    "This section calculates the average of the lowest Mean Absolute Error (MAE) scores across different districts (`ilce`) from the training results. The goal is to summarize the performance of the models by considering the best MAE score for each district.\n",
    "\n",
    "## Steps Involved\n",
    "\n",
    "1. **Initialize List for Lowest Scores**: An empty list `lowest_scores` is initialized to store the lowest MAE scores for each district.\n",
    "2. **Iterate Over Training Results**: Iterate over the `ilce_train_results` dictionary, which contains the training results for each district.\n",
    "3. **Extract Lowest MAE Score for Each District**: For each district, find the lowest MAE score from the available results and append it to the `lowest_scores` list.\n",
    "4. **Calculate Total and Average Scores**: Calculate the total and average of the lowest MAE scores across all districts.\n",
    "5. **Print the Average MAE Score**: Print the calculated average MAE score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowest_scores = []\n",
    "\n",
    "for ilce, results in ilce_train_results.items():\n",
    "    lowest_score = min(result[1] for result in results.values())\n",
    "    lowest_scores.append(lowest_score)\n",
    "\n",
    "total_lowest_score = sum(lowest_scores)\n",
    "average_lowest_score = total_lowest_score / len(ilce_train_results)\n",
    "print(\"Total Average MAE Score:\", average_lowest_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Predictions for Each District\n",
    "\n",
    "This section involves generating predictions for each district (`ilce`) using the best model and its corresponding parameters identified during the training phase. The goal is to use the best model for each district to make predictions on the test data.\n",
    "\n",
    "## Steps Involved\n",
    "\n",
    "1. **Initialize Predictions Dictionary**: An empty dictionary `predictions` is initialized to store the predictions for each district.\n",
    "2. **Iterate Over Training Data**: Iterate over the encoded training dataframes for each district.\n",
    "3. **Select Corresponding Test Data**: For each district, retrieve the corresponding encoded test dataframe.\n",
    "4. **Identify Best Model and Parameters**: Determine the best model and its parameters for each district by iterating over the training results.\n",
    "5. **Generate Predictions**: Use the best model and parameters to generate predictions on the test data for each district.\n",
    "6. **Handle Cases with No Valid Model**: If no valid model is found for a district, print a message and skip the prediction for that district.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {}\n",
    "\n",
    "for ilce, ilce_train_df in ilce_train_encoded_dataframes.items():\n",
    "    ilce_test_df = ilce_test_encoded_dataframes[ilce]\n",
    "    results = ilce_train_results[ilce]\n",
    "    best_model = None\n",
    "    best_score = float('inf') \n",
    "    best_params = None\n",
    "\n",
    "    for model, result in results.items():\n",
    "        if result[1] < best_score:\n",
    "            best_score = result[1]\n",
    "            best_params = result[0]\n",
    "            best_model = model\n",
    "\n",
    "    if best_model:\n",
    "        predictions[ilce] = MLModels(CFG()).process(ilce, ilce_train_df, ilce_test_df, 'ilce', 'bildirimsiz_sum', best_model, best_params)\n",
    "    else:\n",
    "        print(f\"No valid model found for {ilce}. Skipping...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Predictions to Test Data\n",
    "\n",
    "This section involves integrating the predictions generated for each district into the corresponding test dataframes. The function `add_predictions_to_test_data` performs this operation, ensuring that the predicted values are added to the `bildirimsiz_sum` column in the test dataframes.\n",
    "\n",
    "### Parameters\n",
    "- `test_dataframes`: A dictionary of test dataframes for each district.\n",
    "- `predictions`: A dictionary of predictions for each district.\n",
    "\n",
    "### Returns\n",
    "- `test_dataframes`: The updated dictionary of test dataframes with the predictions added.\n",
    "\n",
    "### Steps Involved\n",
    "1. **Iterate Over Predictions**: Iterate over the predictions dictionary.\n",
    "2. **Check for Matching District**: For each district, check if it exists in the test dataframes.\n",
    "3. **Add Predictions**: Add the predicted values to the `bildirimsiz_sum` column in the corresponding test dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_predictions_to_test_data(test_dataframes, predictions):\n",
    "    for ilce, pred_dict in predictions.items():\n",
    "        if ilce in test_dataframes:\n",
    "            test_dataframes[ilce]['bildirimsiz_sum'] = pred_dict[ilce]\n",
    "    return test_dataframes\n",
    "\n",
    "test_dataframes_with_predictions = add_predictions_to_test_data(ilce_test_dataframes, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging Predictions into a Single DataFrame\n",
    "\n",
    "This section involves consolidating the predictions for all districts into a single dataframe. The goal is to create a unified dataframe that contains the predictions for `bildirimsiz_sum` for all districts, along with a unique identifier for each prediction.\n",
    "\n",
    "## Steps Involved\n",
    "\n",
    "1. **Initialize a List for DataFrames**: An empty list `all_dataframes` is initialized to store the individual district dataframes with predictions.\n",
    "2. **Iterate Over Test DataFrames**: Iterate over the test dataframes that contain the predictions.\n",
    "3. **Process Each District's DataFrame**: For each district's dataframe:\n",
    "   - Sort the dataframe by index (date).\n",
    "   - Create a `unique_id` column by combining the date and district name.\n",
    "   - Create a new dataframe with `unique_id` and `bildirimsiz_sum` columns.\n",
    "   - Append the new dataframe to the `all_dataframes` list.\n",
    "4. **Concatenate All DataFrames**: Concatenate all the individual district dataframes into a single dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dataframes = []\n",
    "\n",
    "for ilce, test_df in test_dataframes_with_predictions.items():\n",
    "    if 'bildirimsiz_sum' in test_df.columns:\n",
    "        test_df = test_df.sort_index()\n",
    "        test_df['unique_id'] = test_df.index.strftime('%Y-%m-%d') + '-' + ilce\n",
    "        ilce_df = pd.DataFrame({\n",
    "            'unique_id': test_df['unique_id'],\n",
    "            'bildirimsiz_sum': test_df['bildirimsiz_sum'],\n",
    "        })\n",
    "        all_dataframes.append(ilce_df)\n",
    "\n",
    "merged_df = pd.concat(all_dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the Merged Predictions to CSV\n",
    "\n",
    "This section involves saving the consolidated predictions dataframe to a CSV file. The `merged_df` dataframe, which contains the predictions for `bildirimsiz_sum` for all districts along with unique identifiers, is saved to a specified file path.\n",
    "\n",
    "## Steps Involved\n",
    "\n",
    "1. **Save DataFrame to CSV**: Use the `to_csv` method to save the `merged_df` dataframe to a CSV file. The file is saved without the index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(r\"C:\\Users\\ahmet\\VSCode\\GDZ-Datathon\\submissions\\submission1.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
